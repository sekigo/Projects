{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93831896-683d-4946-8cae-7aff56608a65",
   "metadata": {},
   "source": [
    "## ДЗ №2. Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b424ec-3791-4113-a672-25ef7cfa704d",
   "metadata": {},
   "source": [
    "#### В этой домашке вам предстоит реализовать некоторые базовые модели матричной факторизации\n",
    "\n",
    "#### Дата выдачи: 17.02.25\n",
    "\n",
    "#### Мягкий дедлайн: 02.03.25 23:59 MSK\n",
    "\n",
    "#### Жесткий дедлайн: 09.03.25 23:59 MSK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4b315-75b8-4225-953c-5510c584ff2b",
   "metadata": {},
   "source": [
    "В этом задании мы будем работать с классическим для рекоендательных систем датасетом [MovieLens 1M](https://grouplens.org/datasets/movielens/1m/). Датасет содержит рейтинги оценки для 4000 фильмов от 6000 пользователей. Более подробное описание можете найти на странице с датасетом и в README файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a85f84-4854-4249-963d-143d08bb7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip ml-1m.zip\n",
    "!cat ml-1m/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669137ca-f0f9-48d4-ae04-e42a4b0f8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65b0ae-ce2d-437a-9739-e7981011089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml-1m/ratings.dat\", sep='::', names=['user_id', 'item_id', 'rating', 'timestamp'], engine='python')\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df.drop('timestamp', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988d476-542e-4a32-9c45-7a16bc2a5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['item_id'].value_counts()\n",
    "filtered_values = value_counts[value_counts > 20].index\n",
    "df = df[df['item_id'].isin(filtered_values)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05bd3b-ab2f-4c02-9a97-a4153e9550bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = '2000-12-01'\n",
    "df_train = df[df['datetime'] < train_end].copy()\n",
    "df_test = df[df['datetime'] >= train_end].copy()\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b8ed7-20d6-4778-9d60-f9c8ccbfa7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = df_train['user_id'].unique()\n",
    "train_items = df_train['item_id'].unique()\n",
    "\n",
    "df_test = df_test[df_test['user_id'].isin(train_users)]\n",
    "df_test = df_test[df_test['item_id'].isin(train_items)]\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f53d61-990c-4626-a470-7eefd06d2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_le = LabelEncoder()\n",
    "item_le = LabelEncoder()\n",
    "\n",
    "df_train['user_id'] = user_le.fit_transform(df_train['user_id'])\n",
    "df_train['item_id'] = item_le.fit_transform(df_train['item_id'])\n",
    "\n",
    "df_test['user_id'] = user_le.transform(df_test['user_id'])\n",
    "df_test['item_id'] = item_le.transform(df_test['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef3e2f-792d-4511-b4d0-74495d9cb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['user_id'].nunique(), df_train['user_id'].max()\n",
    "df_train['item_id'].nunique(), df_train['item_id'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d356df8-9157-4752-b30d-dc80aba5e53c",
   "metadata": {},
   "source": [
    "##### Задание 1. Напишем функцию, которая превратит датафрейм в матрицу интеракций. В функции df_to_matrix реализуйте функцию, которая принимает датафрейм и возвращает np.array матрицу интеракций. В функции df_to_coo реализуйте функцию, которая принимает датафрейм и возвращает разреженную матрицу интеракций в coo_array формате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a7bb7-7f2d-4957-8dac-6397af9b1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "\n",
    "    #your code here\n",
    "\n",
    "    return result #shape ~ [n_users, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55362cbb-5e2d-455b-afd1-8507f1dd51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = df_to_matrix(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b646d-a560-42dd-a466-87cad2589271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_array\n",
    "\n",
    "def df_to_coo(df: pd.DataFrame) -> coo_array:\n",
    "\n",
    "    #your code here\n",
    "\n",
    "    return result # coo_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f9c218-0419-41b2-a112-c2214fad1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_interactions = df_to_coo(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b57a7a-0551-4f75-8047-fb9904ac93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (interactions != 0).sum() == df_train.shape[0]\n",
    "assert interactions[0, 2994] == 3\n",
    "assert interactions[2369, 1203] == 5\n",
    "assert interactions[1557, 459] == 3\n",
    "assert np.allclose(coo_interactions.toarray(), interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3862a-e62a-4ebe-a70c-29102e9f99fd",
   "metadata": {},
   "source": [
    "##### Задание 2.1. Рассмотрим [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition). Возьмите готовую реализуцию алгоритма из numpy.linalg или из scipy.linalg и примените алгоритм к матрицам интеракций, полученным в первом задании. Для работы со sparse матрицей обычная реализация svd не подойдет и нужно будет воспользоваться scipy.sparse.linalg.svds. Вам нужно разложить матрицу интеракций на 3 матрицы U, S, V, а затем перемножить их и восстановить изначальную матрицу. При полном разложении исходная матрица должна восстанавливаться максимально хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead134a-9aac-4027-b0b8-592de614c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_svd(interractions: Union[np.ndarray, coo_array], n_singular_values: int = -1):\n",
    "    # функция должна работать и для полной матрицы и для sparse матрицы(вам поможет isinstance).\n",
    "    # если n_singular_values = -1, то берем все сингулярные числа для полной матрицы\n",
    "    # и все кроме одного сингулярного числа для coo-матрицы(иначе scipy.sparse.linalg.svds не будет работать)\n",
    "\n",
    "\n",
    "    #your code here\n",
    "    \n",
    "    return U, S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5fecd4-4739-4f6b-9c9c-44bde8b66a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = make_svd(interactions)\n",
    "assert np.allclose(U @ S @ V, interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5f59e-3832-4a7d-95b4-856531582bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "U1, S1, V1 = make_svd(interactions, 10)\n",
    "U, S, V = make_svd(coo_interactions, 10)\n",
    "assert np.allclose(U1 @ S1 @ V1, U @ S @ V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443daa6-e9f1-414a-8107-5a3016452929",
   "metadata": {},
   "source": [
    "##### Задание 2.2. Теперь попробуем сделать рекомендации с помощью SVD. Мы научились восстанавливать исходную матрицу с помощью разложения, теперь же мы хотим порекомендовать пользователю айтемы, которые будут для него максимально релевантны(в восстановленной матрице у них будет самый высокий скор). Для каждого пользователя нужно будет найти индексы айтемов, которые имеют максимальный скор. При этом стоит обратить внимание, что мы не хотим рекомендовать пользователю айтемы, с которыми он уже взаимодействовал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787da18f-48d0-4dfa-b18f-b7e97cc98a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_svd_recommendations(interractions: Union[np.ndarray, coo_array], n_singular_values: int = -1, top_k: int = 100):\n",
    "    # Возвращает матрицу вида n_users, top_k, то есть для каждого пользователя возвращаем индексы \n",
    "    # top_k самых релевантный айтемов среди тех с которыми он еще не взаимодействовал\n",
    "\n",
    "    #your code here\n",
    "\n",
    "\n",
    "    return recommendations #shape ~ [n_users, top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72f3dd-c8f2-4434-b84e-ef016c4773a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = make_svd_recommendations(interractions, -1, 100)\n",
    "assert recs.shape == (interractions.shape[0], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0b788-855a-4fd9-8cbb-38c0dd289ef5",
   "metadata": {},
   "source": [
    "##### Задание 2.3. Теперь давайте посмотрим как будет зависеть качетво рекомендаций, от количества сингулярных чисел, которые мы возьмем в SVD разложении. Переберите n_singular_values из списка [1, 10, 50, 200, 1000] и посмотрите как будет изменяться метрика NDCG на тестовом датасете для таких рекомендаций и как будет меняться время вычисления. Для каждого графики зависимости метрики NDCG от n_singular_values и времени работы алгоритма от n_singular_values(Время работы будет меняться только для sparse-матрицы, стоит запускать алгоритм именно для нее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f931fd-0eb0-4965-9e02-e005ed545c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(interractions: Union[np.ndarray, coo_array], top_k: int = 100):\n",
    "    #your code here\n",
    "    for n_singular_values in [1, 10, 50, 200, 1000]:\n",
    "        #your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22fe02-b1c2-4fb5-a7b1-0525356fe9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8612d96-c694-42d6-9525-58808f642577",
   "metadata": {},
   "source": [
    "##### Задание 3.1. Перейдем к [ALS](http://yifanhu.net/PUB/cf.pdf). Возьмем реализацию iALS из библиотеки [implicit](https://benfred.github.io/implicit/api/models/cpu/als.html). Обучите ALS на нашем датасете, сделайте top_k рекомендации для юзеров из тестового датасета, и сравните метрики ALS с метриками, которые получились в SVD. Попробуйте перебрать гиперпараметры и найдите оптимальное число факторов, коэффициент alpha и коэффициент регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb16e9-49d1-4d7e-a384-ccbdad4f1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_als_recommendations(\n",
    "    interractions: Union[np.ndarray, coo_array], \n",
    "    top_k: int = 100, \n",
    "    n_factors: int = 100,\n",
    "    alpha: float = 1.0,\n",
    "    regularization: float = 0.01,\n",
    "):\n",
    "    #your code here\n",
    "\n",
    "\n",
    "    return recommendations #shape ~ [n_users, top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5573d01-8512-450f-9260-03928ee9b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = make_als_recommendations(interractions)\n",
    "assert recs.shape == (interractions.shape[0], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3b1cc-760b-4d6a-ab8a-aca57b7b6dfe",
   "metadata": {},
   "source": [
    "##### Задание 3.2. Сделайте объяснение рекомендаций для нескольких юзеров(als.explain). Воспользуйтесь файлом movies.dat чтобы перейти от индексов фильмов к их названием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9a956-d2f5-4560-8d0c-c72164ebdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7ea0c-8288-45f5-83d4-9761a8952669",
   "metadata": {},
   "source": [
    "##### Задание 4. До этого мы работали с рейтингами, но как обсуждалось на лекции, implicit ALS отлично работает и с implicit фидбэком. Давайте попробуем преобразовать наш датасет(трейн и тест) следующим образом\n",
    "\n",
    "1. Бинаризуем все рейтинги(заменим любую интеракцию пользователя на 1)\n",
    "2. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на 0\n",
    "3. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на -1\n",
    "4. Заменим на 1 только рейтинги 4 и 5, а рейтинг ниже 4 заменим на -1 и добавим сглаживание по времени. То есть чем дальше была интеракция от максимальной даты трейна, тем с меньшим весом мы будем ее учитывать(например можно интеракции за последний месяц брать в исходном виде, и с каждым месяцем в прошлое умножать их на какой-нибудь коэффициент меньший 1). Таким образом более старые интеракции пользователя будут вносить меньший вклад в его интересы\n",
    "5. Придумайте свой вариант(опционально)\n",
    "\n",
    "Для каждой полученной матрицы обучите iALS и SVD и сравните их результаты между собой(преобразовывать нужно только обучающую выборку, тестовую оставляем неизменной)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839fd09-eca4-43e0-a209-2da63775f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a03b1-5072-4bc4-ba46-1fc3c989b888",
   "metadata": {},
   "source": [
    "##### Задание 5. iALS на numpy/torch. Давайте реализуем алгоритм iALS на нумпае или торче. Требуется реализовать алгорит, описанный в 4 части [статьи](http://yifanhu.net/PUB/cf.pdf). Обратите внимания на все оптимизации, которые они описывают в статье, чтобы сократить лишние вычисления. Hint: метрики у вашего алгоритма должны быть сравнимы с метриками ALS из библиотеки implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be5f0d-1454-4f15-9dd1-17d1f1f99583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iALS:\n",
    "    def __init__(self, n_factors: int = 100, alpha: float = 1.0, reg_coef = 0.01):\n",
    "        #your code here\n",
    "\n",
    "    def fit(self, interractions: np.ndarray, n_iterations: int 10):\n",
    "        #your code here\n",
    "\n",
    "    def predict(self, top_k: int = 100):\n",
    "        # возвращает top-k айтемов для каждого юзера(айтемы с которыми юзер взаимодействовал не должны попасть в рекомендации)\n",
    "        #your code here\n",
    "\n",
    "        return predicts # shape ~ [n_users, top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa65d7-11dc-48d9-a270-8d0a6d96f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_course",
   "language": "python",
   "name": "recsys_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
